{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gustapfp/2025.2-G4-bovenau-protalent/blob/main/src/experiments/jupyter/yolo_trainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Yolo Training Model\n",
        "This Jupyter Notebook its used for training a Yolo Model for Welding Detection.\n",
        "\n",
        "## 1. Introduction\n",
        "\n",
        "This notebook uses [Ultralytics](https://docs.ultralytics.com/) to train YOLO11, YOLOv8, or YOLOv5 object detection models with a custom dataset. At the end of this Colab, you'll have a custom YOLO model that you can run on your PC, phone, or edge device like the Raspberry Pi.\n",
        "\n",
        "<p align=center>\n",
        "<img src=\"https://s3.us-west-1.amazonaws.com/evanjuras.com/img/yolo-model-demo.gif\" height=\"360\"><br>\n",
        "<i>Custom YOLO candy detection model in action!</i>\n",
        "</p>"
      ],
      "metadata": {
        "id": "akZJFQsHlhC6"
      },
      "id": "akZJFQsHlhC6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Verify NVIDIA GPU Availability\n",
        "\n",
        "Make sure you're using a GPU-equipped machine by going to \"Runtime\" -> \"Change runtime type\" in the top menu bar, and then selecting one of the GPU options in the Hardware accelerator section. Click Play on the following code block to verify that the NVIDIA GPU is present and ready for training."
      ],
      "metadata": {
        "id": "mF5mlavvl1Wo"
      },
      "id": "mF5mlavvl1Wo"
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTYxGYJjlzmn",
        "outputId": "6233dc48-8fcb-4e68-ab9f-40d2357a5600"
      },
      "id": "DTYxGYJjlzmn",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Sep 14 14:18:53 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   63C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Upload Images\n",
        "Upload .zip folder into colab instance and them split the images"
      ],
      "metadata": {
        "id": "6bnnr0PLpQRD"
      },
      "id": "6bnnr0PLpQRD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1  Split images into train and validation folders\n",
        "At this point, whether you used Option 1, 2, or 3, you should be able to click the folder icon on the left and see your `archive.zip` file in the list of files. Next, we'll unzip `archive.zip` and create some folders to hold the images. Run the following code block to unzip the data."
      ],
      "metadata": {
        "id": "1HEdnVqNpYLF"
      },
      "id": "1HEdnVqNpYLF"
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/archive.zip -d /content/custom_data"
      ],
      "metadata": {
        "id": "GlDoE_0lpUxv"
      },
      "id": "GlDoE_0lpUxv",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ultralytics requires a particular folder structure to store training data for models. Ultralytics requires a particular folder structure to store training data for models. The root folder is named ‚Äúdata‚Äù. Inside, there are two main folders:\n",
        "\n",
        "*   **Train**: These are the actual images used to train the model. In one epoch of training, every image in the train set is passed into the neural network. The training algorithm adjusts the network weights to fit the data in the images.\n",
        "\n",
        "* **Test**: These images are used only after training is completed, to evaluate the model on unseen data and measure its generalization ability.\n",
        "\n",
        "\n",
        "*   **Validation**: These images are used to check the model's performance at the end of each training epoch.\n",
        "\n",
        "In each of these folders is a ‚Äúimages‚Äù folder and a ‚Äúlabels‚Äù folder, which hold the image files and annotation files respectively."
      ],
      "metadata": {
        "id": "1Pcj9JtlqN5F"
      },
      "id": "1Pcj9JtlqN5F"
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the dataset doesn't have this folder structure already, run this Python script which will automatically create the required folder structure and randomly move 90% of dataset to the \"train\" folder and 10% to the \"validation\" folder. Run the following code block to download and execute the scrpt.\n",
        "\n",
        "*The python script was made by: Evan Juras, [EJ Technology Consultants](https://ejtech.io)*"
      ],
      "metadata": {
        "id": "6mm95pLRqs7V"
      },
      "id": "6mm95pLRqs7V"
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the comment here:\n",
        "# !wget -O /content/train_val_split.py https://raw.githubusercontent.com/EdjeElectronics/Train-and-Deploy-YOLO-Models/refs/heads/main/utils/train_val_split.py\n",
        "\n",
        "# TO DO: Improve robustness of train_val_split.py script so it can handle nested data folders, etc\n",
        "# Remove the comment here:\n",
        "# !python train_val_split.py --datapath=\"/content/custom_data\" --train_pct=0.9"
      ],
      "metadata": {
        "id": "pqXPPlvvqitr"
      },
      "id": "pqXPPlvvqitr",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Install the Requirements\n",
        "Before training or testing YOLO models, you need to install the Ultralytics package and its dependencies. This can be done directly from PyPI:"
      ],
      "metadata": {
        "id": "t6hn8Bl1sJsS"
      },
      "id": "t6hn8Bl1sJsS"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "ocfVQGGbrB3z"
      },
      "id": "ocfVQGGbrB3z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Once installed, you can check if everything is working by importing the package and printing its version:\n",
        "\n",
        "The `ultralytics.checks()` command verifies that your environment (CUDA, PyTorch, and dependencies) is correctly set up for training and inference."
      ],
      "metadata": {
        "id": "unfhAcwEsw7Z"
      },
      "id": "unfhAcwEsw7Z"
    },
    {
      "cell_type": "code",
      "source": [
        "import ultralytics\n",
        "ultralytics.checks()\n"
      ],
      "metadata": {
        "id": "HaMgJLQIs096",
        "outputId": "1e33d078-333b-4593-cbde-fb01091377f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "HaMgJLQIs096",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.199 üöÄ Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Setup complete ‚úÖ (2 CPUs, 12.7 GB RAM, 39.3/112.6 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Tip: If you are working in Google Colab, the installation will only persist while the runtime is active. You‚Äôll need to run the installation cell each time you restart the runtime.*"
      ],
      "metadata": {
        "id": "jXUB0Nv7s8FM"
      },
      "id": "jXUB0Nv7s8FM"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mPd1w-iltBfZ"
      },
      "id": "mPd1w-iltBfZ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}